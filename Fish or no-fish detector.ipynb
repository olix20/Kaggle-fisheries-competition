{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import utils#; reload(utils)\n",
    "from utils import *\n",
    "from __future__ import division, print_function\n",
    "\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import iglob, glob\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "from scipy.misc import imresize, toimage\n",
    "\n",
    "\n",
    "ROOT_DIR = os.getcwd()\n",
    "DATA_HOME_DIR = ROOT_DIR + '/data/'\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_HOME_DIR\n",
    "path = DATA_HOME_DIR+\"fishnofish/\"\n",
    "batch_size=32\n",
    "target_size = (360,640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3327 images belonging to 2 classes.\n",
      "Found 450 images belonging to 2 classes.\n",
      "Found 12153 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "#path = \"data/fish/sample/\"\n",
    "\n",
    "\n",
    "\n",
    "(val_classes, trn_classes, val_labels, trn_labels, \n",
    "    val_filenames, filenames, test_filenames) = get_classes(path)\n",
    "\n",
    "raw_filenames = [f.split('/')[-1] for f in filenames]\n",
    "raw_test_filenames = [f.split('/')[-1] for f in test_filenames]\n",
    "raw_val_filenames = [f.split('/')[-1] for f in val_filenames]\n",
    "\n",
    "# raw_val_filenames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,f in enumerate(raw_test_filenames):\n",
    "    raw_test_filenames[i] = \"test_stg2/\"+raw_test_filenames[i] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(\"data/stg2_raw_test_filenames.dat\",raw_test_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trn = load_array(path+'results/trn_640.dat')\n",
    "# val = load_array(path+'results/val_640.dat')\n",
    "# test = load_array(path+'results/test_640.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# conv_val_feat = load_array(DATA_HOME_DIR+'results/conv_val_640.dat')\n",
    "# conv_trn_feat = load_array(DATA_HOME_DIR+'results/conv_trn_640.dat')\n",
    "# conv_test_feat = load_array(DATA_HOME_DIR+'results/conv_test_640.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 3, 360, 640) (None, 512, 22, 40)\n"
     ]
    }
   ],
   "source": [
    "# vgg640 = Vgg16BN((360, 640)).model\n",
    "# vgg640.pop()\n",
    "# print (vgg640.input_shape, vgg640.output_shape)\n",
    "# vgg640.compile(Adam(), 'categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# conv_layers,_ = split_at(vgg640, Convolution2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3327 images belonging to 2 classes.\n",
      "Found 450 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = image.ImageDataGenerator(\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        rotation_range=7.,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "\n",
    "# set shuffle=False if pre-computing\n",
    "\n",
    "trn_flow = train_datagen.flow_from_directory(path+'train', target_size=target_size,\n",
    "           class_mode='categorical', shuffle=True, batch_size=batch_size)\n",
    "\n",
    "\n",
    "val_flow = image.ImageDataGenerator().flow_from_directory(path+\"valid\", target_size=target_size, batch_size=batch_size,\n",
    "                                                   class_mode='categorical', shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### precomputing augmented vgg features \n",
    "\n",
    "Memory issues, skipping this and doing a full net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# da_conv_feat = vgg640.predict_generator(aug_trn_batches, aug_trn_batches.nb_sample*5)\n",
    "\n",
    "# save_array(path+'results/aug_trn_feat1.dat', da_conv_feat)\n",
    "# da_conv_feat = load_array(path+'results/aug_trn_feat1.dat')\n",
    "#da_conv_feat = da_conv_feat[0:aug_trn_batches.nb_sample*3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#Let's include the real training data as well in its non-augmented form.\n",
    "# da_conv_feat = np.concatenate([da_conv_feat, conv_trn_feat])\n",
    "\n",
    "#Since we've now got a dataset 6x bigger than before, we'll need to copy our labels 6 times too.\n",
    "#da_trn_labels = np.concatenate([trn_labels]*3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nf=128; p=0.\n",
    "\n",
    "# from keras.layers.pooling import GlobalMaxPooling2D\n",
    "def get_lrg_layers():\n",
    "    return [\n",
    "        BatchNormalization(axis=1, input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(nf,3,3, activation='relu', border_mode='same'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D((1,2)),\n",
    "        Convolution2D(2,3,3, border_mode='same'), #fish/no fish\n",
    "        Dropout(p),\n",
    "        GlobalAveragePooling2D(), #change to Max\n",
    "#         GlobalMaxPooling2D(),\n",
    "        Activation('softmax')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.py:1282: UserWarning: DEPRECATION: the 'ds' parameter is not going to exist anymore as it is going to be replaced by the parameter 'ws'.\n",
      "  mode='max')\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.py:1282: UserWarning: DEPRECATION: the 'st' parameter is not going to exist anymore as it is going to be replaced by the parameter 'stride'.\n",
      "  mode='max')\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.py:1282: UserWarning: DEPRECATION: the 'padding' parameter is not going to exist anymore as it is going to be replaced by the parameter 'pad'.\n",
      "  mode='max')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th\n",
      "(None, 3, 360, 640) (None, 2)\n"
     ]
    }
   ],
   "source": [
    "model = Vgg16BN(target_size).model #(360, 640)\n",
    "model.pop()\n",
    "\n",
    "for layer in model.layers: #Freeze feature layers\n",
    "    layer.trainable = False\n",
    "    \n",
    "    \n",
    "    \n",
    "conv_layers,_ = split_at(model, Convolution2D)\n",
    "\n",
    "for l in get_lrg_layers():\n",
    "    model.add(l)\n",
    "    \n",
    "print (model.input_shape, model.output_shape)\n",
    "\n",
    "early_stopping  = keras.callbacks.EarlyStopping(monitor='val_loss', patience=1)\n",
    "\n",
    "\n",
    "model.compile(Adam(lr=0.001), 'categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if precomputing \n",
    "\n",
    "#model = Sequential(get_lrg_layers())\n",
    "#model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3327/3327 [==============================] - 484s - loss: 0.1581 - acc: 0.9480 - val_loss: 0.3058 - val_acc: 0.9200\n",
      "Epoch 2/5\n",
      "3327/3327 [==============================] - 482s - loss: 0.0843 - acc: 0.9735 - val_loss: 0.2508 - val_acc: 0.9467\n",
      "Epoch 3/5\n",
      "3327/3327 [==============================] - 482s - loss: 0.0562 - acc: 0.9814 - val_loss: 0.1019 - val_acc: 0.9800\n",
      "Epoch 4/5\n",
      "3327/3327 [==============================] - 482s - loss: 0.0434 - acc: 0.9844 - val_loss: 0.1868 - val_acc: 0.9533\n",
      "Epoch 5/5\n",
      "3327/3327 [==============================] - 482s - loss: 0.0368 - acc: 0.9862 - val_loss: 0.0800 - val_acc: 0.9778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f41d4e27c90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(trn_flow, samples_per_epoch=trn_flow.nb_sample, \n",
    "                    nb_epoch=5,\n",
    "                    validation_data=val_flow, nb_val_samples=val_flow.nb_sample,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i'll use these weights for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.save_weights(path+\"models/fcn_aug_1e3_5epc_val_acc_0.9778.hd5\")\n",
    "model.load_weights(path+\"models/fcn_aug_1e3_5epc_val_acc_0.9778.hd5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3327/3327 [==============================] - 483s - loss: 0.0286 - acc: 0.9898 - val_loss: 0.1028 - val_acc: 0.9756\n",
      "Epoch 2/5\n",
      "3327/3327 [==============================] - 482s - loss: 0.0274 - acc: 0.9922 - val_loss: 0.1634 - val_acc: 0.9711\n",
      "Epoch 3/5\n",
      "3327/3327 [==============================] - 481s - loss: 0.0194 - acc: 0.9943 - val_loss: 0.1656 - val_acc: 0.9689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f41b8329350>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-4\n",
    "model.fit_generator(trn_flow, samples_per_epoch=trn_flow.nb_sample, \n",
    "                    nb_epoch=5,\n",
    "                    validation_data=val_flow, nb_val_samples=val_flow.nb_sample,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model.save_weights(path+\"models/fcn_aug_1e4_3epc_val_acc_0.9778.hd5\") #should have been 0.9689\n",
    "model.load_weights(path+\"models/fcn_aug_1e4_3epc_val_acc_0.9778.hd5\") #should have been 0.9689 #ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Making last 2 layer of VGG trainable (ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model.layers[-18:-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in model.layers[-18:-14]:\n",
    "    layer.trainable = True     #didn't really improve results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3327/3327 [==============================] - 509s - loss: 0.0286 - acc: 0.9907 - val_loss: 0.1824 - val_acc: 0.9644\n",
      "Epoch 2/3\n",
      "3327/3327 [==============================] - 505s - loss: 0.0238 - acc: 0.9940 - val_loss: 0.2324 - val_acc: 0.9533\n",
      "Epoch 3/3\n",
      "3327/3327 [==============================] - 505s - loss: 0.0282 - acc: 0.9916 - val_loss: 0.2169 - val_acc: 0.9622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fce3448dbd0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-6\n",
    "\n",
    "model_fn = path+\"models/\" + 'fcn_aug_vggtunetop2_{val_acc:.2f}_{val_acc:.2f}val_acc-{val_loss:.2f}-loss_{epoch}epoch_ie6.h5' \n",
    "ckpt = ModelCheckpoint(filepath=model_fn, monitor='val_loss',\n",
    "                           save_best_only=True, save_weights_only=True)\n",
    "\n",
    "model.fit_generator(trn_flow, samples_per_epoch=trn_flow.nb_sample, \n",
    "                    nb_epoch=3,\n",
    "                    validation_data=val_flow, nb_val_samples=val_flow.nb_sample,\n",
    "                    callbacks=[early_stopping,ckpt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3327/3327 [==============================] - 508s - loss: 0.0185 - acc: 0.9937 - val_loss: 0.1836 - val_acc: 0.9644\n",
      "Epoch 2/3\n",
      "3327/3327 [==============================] - 507s - loss: 0.0247 - acc: 0.9925 - val_loss: 0.2014 - val_acc: 0.9644\n",
      "Epoch 3/3\n",
      "3327/3327 [==============================] - 507s - loss: 0.0249 - acc: 0.9925 - val_loss: 0.1551 - val_acc: 0.9689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fce1a720590>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-7\n",
    "\n",
    "model_fn = path+\"models/\" + 'fcn_aug_vggtunetop2_{val_acc:.2f}_{val_acc:.2f}val_acc-{val_loss:.2f}-loss_{epoch}epoch_1e7.h5' \n",
    "ckpt = ModelCheckpoint(filepath=model_fn, monitor='val_loss',\n",
    "                           save_best_only=True, save_weights_only=True)\n",
    "\n",
    "model.fit_generator(trn_flow, samples_per_epoch=trn_flow.nb_sample, \n",
    "                    nb_epoch=3,\n",
    "                    validation_data=val_flow, nb_val_samples=val_flow.nb_sample,\n",
    "                    callbacks=[early_stopping,ckpt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model.save_weights(path+\"models/fcn_aug_vggtunetop2_1e5_3epc_val_acc_0.9844.h5\")\n",
    "# model.load_weights(path+\"models/fcn_aug_vggtunetop2_1e5_3epc_val_acc_0.9844.h5\") >> doesn't exist! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions \n",
    "With test augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12153 images belonging to 1 classes.\n",
      "finished predicting round 1\n",
      "Found 12153 images belonging to 1 classes.\n",
      "finished predicting round 2\n",
      "Found 12153 images belonging to 1 classes.\n",
      "finished predicting round 3\n",
      "Found 12153 images belonging to 1 classes.\n",
      "finished predicting round 4\n",
      "Found 12153 images belonging to 1 classes.\n",
      "finished predicting round 5\n"
     ]
    }
   ],
   "source": [
    "test_datagen = train_datagen\n",
    "num_iterations = 5\n",
    "preds = np.zeros((len(test_filenames), 2)) #1000 test images, fish or no fish probs \n",
    "\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    test_gen = test_datagen.flow_from_directory(path+\"test\", target_size=target_size, batch_size=batch_size,\n",
    "                                                        class_mode=None, shuffle=False)\n",
    "    preds += model.predict_generator(test_gen, val_samples=len(test_filenames))\n",
    "    \n",
    "    print (\"finished predicting round {}\".format(i+1))\n",
    "    save_array(path+\"results/stg2_pred_fullconv_aug_no_pseudo_part{}.dat\".format(i+1),preds)\n",
    "    \n",
    "averaged_preds = preds / num_iterations  \n",
    "# save_array(path+\"results/pred_stg1_fullconv_aug_no_pseudo.dat\",averaged_preds)\n",
    "save_array(path+\"results/stg2_pred_fullconv_aug_no_pseudo.dat\",averaged_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Pseudo labeling \n",
    "Using test and validation predictions to strenghten the model \n",
    "\n",
    "wrongly implemented, and most probably overfits to training set, ignoring the results in this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MixIterator(object):\n",
    "    def __init__(self, iters):\n",
    "        self.iters = iters\n",
    "        self.multi = type(iters) is list\n",
    "#         if self.multi:\n",
    "#             self.N = sum([it[0].N for it in self.iters])\n",
    "#         else:\n",
    "        self.N = sum([it.N for it in self.iters])\n",
    "\n",
    "    def reset(self):\n",
    "        for it in self.iters: it.reset()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def next(self, *args, **kwargs):\n",
    "#         if self.multi:\n",
    "#             nexts = [[next(it) for it in o] for o in self.iters]\n",
    "#             n0s = np.concatenate([n[0] for n in o])\n",
    "#             n1s = np.concatenate([n[1] for n in o])\n",
    "#             return (n0, n1)\n",
    "#         else:\n",
    "        nexts = [next(it) for it in self.iters]\n",
    "        n0 = np.concatenate([n[0] for n in nexts])\n",
    "        n1 = np.concatenate([n[1] for n in nexts])\n",
    "        return (n0, n1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trn = load_array(path+'results/trn_640.dat')\n",
    "# val = load_array(path+'results/val_640.dat')\n",
    "# test = load_array(path+'results/test_640.dat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3327 images belonging to 2 classes.\n",
      "Found 450 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# gen = image.DataGenerator()\n",
    "# test_flow = train_datagen.flow_from_directory(path+\"test\", target_size=target_size, batch_size=batch_size,\n",
    "#                                                         class_mode=None, shuffle=False)\n",
    "\n",
    "\n",
    "trn_batch = train_datagen.flow_from_directory(path+'train', target_size=target_size,\n",
    "           class_mode='categorical', shuffle=True, batch_size=22) #67% of 32\n",
    "\n",
    "val_batch = train_datagen.flow_from_directory(path+\"valid\", target_size=target_size, batch_size=2,\n",
    "                                                   class_mode='categorical', shuffle=True)\n",
    "\n",
    "#i'm actually making a mistake to use validation set results, by right, i should be using predictions of the model as labels \n",
    "#but i'm making a concious choice to train on full training set\n",
    "\n",
    "gen = image.ImageDataGenerator()\n",
    "\n",
    "# train_datagen\n",
    "# trn_batch  = gen.flow(trn,trn_labels,batch_size=22)\n",
    "# val_batch  = gen.flow(val,val_labels,batch_size=2)\n",
    "\n",
    "# test_batch = train_datagen.flow(test,averaged_preds,batch_size=8)\n",
    "\n",
    "#using ensumbled weights instead\n",
    "test_batch = train_datagen.flow(test,final_stg1_weights,batch_size=8,shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mi = MixIterator([trn_batch, val_batch,test_batch])\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4768/4777 [============================>.] - ETA: 1s - loss: 0.0638 - acc: 0.9847"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.py:1462: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800/4777 [==============================] - 670s - loss: 0.0636 - acc: 0.9848 - val_loss: 0.0632 - val_acc: 0.9800\n",
      "Epoch 2/5\n",
      "4783/4777 [==============================] - 667s - loss: 0.0519 - acc: 0.9868 - val_loss: 0.0282 - val_acc: 0.9889\n",
      "Epoch 3/5\n",
      "4783/4777 [==============================] - 667s - loss: 0.0423 - acc: 0.9923 - val_loss: 0.0196 - val_acc: 0.9933\n",
      "Epoch 4/5\n",
      "4783/4777 [==============================] - 667s - loss: 0.0457 - acc: 0.9904 - val_loss: 0.0211 - val_acc: 0.9889\n",
      "Epoch 5/5\n",
      "4783/4777 [==============================] - 667s - loss: 0.0415 - acc: 0.9923 - val_loss: 0.0061 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f41b5361950>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "model.fit_generator(mi, mi.N, \n",
    "                    nb_epoch=5,\n",
    "                    validation_data=val_flow, nb_val_samples=val_flow.nb_sample,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a risk of overfitting by including full validation set (and labels) during training, but i use the resutls anyway, \n",
    "because i trust the network has sufficient means not to overfit (global average pooling)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(path+\"models/fcn_aug_pseduo_1e5_5epc_val_acc_1.0.hd5\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating predictions for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 1 classes.\n",
      "finished predicting round 1\n",
      "Found 1000 images belonging to 1 classes.\n",
      "finished predicting round 2\n",
      "Found 1000 images belonging to 1 classes.\n",
      "finished predicting round 3\n",
      "Found 1000 images belonging to 1 classes.\n",
      "finished predicting round 4\n",
      "Found 1000 images belonging to 1 classes.\n",
      "finished predicting round 5\n"
     ]
    }
   ],
   "source": [
    "test_datagen = train_datagen\n",
    "num_iterations = 5\n",
    "preds = np.zeros((1000, 2)) #1000 test images, fish or no fish probs \n",
    "\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    test_gen = test_datagen.flow_from_directory(path+\"test\", target_size=target_size, batch_size=batch_size,\n",
    "                                                        class_mode=None, shuffle=False)\n",
    "    preds += model.predict_generator(test_gen, val_samples=1000)\n",
    "    print (\"finished predicting round {}\".format(i+1))\n",
    "    \n",
    "    \n",
    "averaged_preds = preds / num_iterations  \n",
    "save_array(path+\"results/pred_stg1_fullconv_aug_WITH_pseudo.dat\",averaged_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##  Fully Connected on top\n",
    "This is one of the models i created in the beginning. \n",
    "Using the probs for bagging with the fully conv net model above, reuslts in 0.03 improvement in final score\n",
    "\n",
    "I should have done training and test augmentation here, but it's too late for second stage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3327 images belonging to 2 classes.\n",
      "Found 450 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# trn = get_data(path+'train', (360,640))\n",
    "# val = get_data(path+'valid', (360,640))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12153 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test = get_data(path+'test', (360,640))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(path+'results/stg2_test_640.dat', test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '/home/ubuntu/fish/data/fishnofish/results/stg2_test_640.dat/meta/sizes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7b3c832a4fdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# trn = load_array(path+'results/trn_640.dat')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# val = load_array(path+'results/val_640.dat')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'results/stg2_test_640.dat'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#was val_640.dat i hope i've not messed up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/fish/utils.pyc\u001b[0m in \u001b[0;36mload_array\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbcolz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/bcolz/toplevel.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(rootdir, mode)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbcolz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrootdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrootdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbcolz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrootdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrootdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mbcolz/carray_ext.pyx\u001b[0m in \u001b[0;36mbcolz.carray_ext.carray.__cinit__ (bcolz/carray_ext.c:13429)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mbcolz/carray_ext.pyx\u001b[0m in \u001b[0;36mbcolz.carray_ext.carray._read_meta (bcolz/carray_ext.c:17967)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/home/ubuntu/fish/data/fishnofish/results/stg2_test_640.dat/meta/sizes'"
     ]
    }
   ],
   "source": [
    "# save_array(path+'results/trn_640.dat', trn)\n",
    "# save_array(path+'results/val_640.dat', val)\n",
    "\n",
    "# trn = load_array(path+'results/trn_640.dat')\n",
    "# val = load_array(path+'results/val_640.dat')\n",
    "test = load_array(path+'results/stg2_test_640.dat') #was val_640.dat i hope i've not messed up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3327, 3, 360, 640), (450, 3, 360, 640))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn.shape, val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.py:1282: UserWarning: DEPRECATION: the 'ds' parameter is not going to exist anymore as it is going to be replaced by the parameter 'ws'.\n",
      "  mode='max')\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.py:1282: UserWarning: DEPRECATION: the 'st' parameter is not going to exist anymore as it is going to be replaced by the parameter 'stride'.\n",
      "  mode='max')\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.py:1282: UserWarning: DEPRECATION: the 'padding' parameter is not going to exist anymore as it is going to be replaced by the parameter 'pad'.\n",
      "  mode='max')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 3, 360, 640) (None, 512, 22, 40)\n"
     ]
    }
   ],
   "source": [
    "from vgg16bn import Vgg16BN\n",
    "# # # model = vgg_ft_bn(2)\n",
    "vgg640 = Vgg16BN(size=(360, 640)).model\n",
    "\n",
    "vgg640.pop()\n",
    "print (vgg640.input_shape, vgg640.output_shape)\n",
    "vgg640.compile(Adam(), 'categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# vgg640.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# trn = load_array(path+'results/trn.dat')\n",
    "# val = load_array(path+'results/val.dat')\n",
    "\n",
    "# gen = image.ImageDataGenerator()\n",
    "# model.compile(optimizer=Adam(1e-3),\n",
    "#        loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # model.fit(trn, trn_labels, batch_size=batch_size, nb_epoch=3, validation_data=(val, val_labels))\n",
    "\n",
    "# model.load_weights(path+'results/ft1.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conv_layers,fc_layers = split_at(vgg640, Convolution2D)\n",
    "conv_model = Sequential(conv_layers)\n",
    "\n",
    "# conv_feat = conv_model.predict(trn)\n",
    "# conv_val_feat = conv_model.predict(val)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(path+'results/conv_val_feat_640.dat', conv_val_feat)\n",
    "save_array(path+'results/conv_feat_640.dat', conv_feat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_test_feat = conv_model.predict(test)\n",
    "save_array(path+'results/stg2_conv_test_feat_640.dat', conv_test_feat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_bn_layers(p):\n",
    "    return [\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        BatchNormalization(axis=1),\n",
    "        Dropout(p/4),\n",
    "        Flatten(),\n",
    "        Dense(1024, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(1024, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p/2),\n",
    "        Dense(2, activation='softmax')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load 640 version instead .. \n",
    "# conv_feat = load_array(DATA_HOME_DIR+'results/conv_feat_640.dat')\n",
    "# conv_val_feat = load_array(DATA_HOME_DIR+'results/conv_val_feat_640.dat')\n",
    "# conv_test_feat = load_array(DATA_HOME_DIR+'results/conv_test_feat_640.dat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = 0.6\n",
    "# bn_model = vgg_ft_bn(1)\n",
    "# conv_layers,fc_layers = split_at(vgg640, Convolution2D)\n",
    "\n",
    "bn_model = Sequential(get_bn_layers(p))\n",
    "bn_model.compile(Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# bn_model = Sequential(get_bn_layers(p))\n",
    "# bn_model.compile(Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((None, 3, 360, 640), (None, 512, 22, 40))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model.input_shape,conv_model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# bn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3327, 512, 22, 40) (None, 512, 22, 40)\n",
      "Train on 3327 samples, validate on 450 samples\n",
      "Epoch 1/3\n",
      "3327/3327 [==============================] - 25s - loss: 0.5895 - acc: 0.7463 - val_loss: 0.2273 - val_acc: 0.9356\n",
      "Epoch 2/3\n",
      "3327/3327 [==============================] - 25s - loss: 0.3039 - acc: 0.8783 - val_loss: 0.1702 - val_acc: 0.9600\n",
      "Epoch 3/3\n",
      "3327/3327 [==============================] - 25s - loss: 0.1797 - acc: 0.9351 - val_loss: 0.1246 - val_acc: 0.9800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8df1559f90>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (conv_feat.shape,bn_model.input_shape)\n",
    "\n",
    "bn_model.fit(conv_feat, to_categorical(trn_classes), batch_size=batch_size, nb_epoch=3, \n",
    "             validation_data=(conv_val_feat, to_categorical(val_classes)))\n",
    "\n",
    "# bn_model.fit(conv_feat, trn_classes, batch_size=batch_size, nb_epoch=3, \n",
    "#              validation_data=(conv_val_feat, val_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3327 samples, validate on 450 samples\n",
      "Epoch 1/3\n",
      "3327/3327 [==============================] - 25s - loss: 0.1345 - acc: 0.9492 - val_loss: 0.2301 - val_acc: 0.9644\n",
      "Epoch 2/3\n",
      "3327/3327 [==============================] - 25s - loss: 0.1195 - acc: 0.9600 - val_loss: 0.1605 - val_acc: 0.9711\n",
      "Epoch 3/3\n",
      "3327/3327 [==============================] - 25s - loss: 0.0888 - acc: 0.9723 - val_loss: 0.1726 - val_acc: 0.9711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8df3358290>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_model.fit(conv_feat, to_categorical(trn_classes), batch_size=batch_size, nb_epoch=3, \n",
    "             validation_data=(conv_val_feat, to_categorical(val_classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3327 samples, validate on 450 samples\n",
      "Epoch 1/5\n",
      "3327/3327 [==============================] - 25s - loss: 0.0386 - acc: 0.9889 - val_loss: 0.2028 - val_acc: 0.9711\n",
      "Epoch 2/5\n",
      "3327/3327 [==============================] - 25s - loss: 0.0442 - acc: 0.9874 - val_loss: 0.1861 - val_acc: 0.9733\n",
      "Epoch 3/5\n",
      "3327/3327 [==============================] - 25s - loss: 0.0348 - acc: 0.9904 - val_loss: 0.1734 - val_acc: 0.9778\n",
      "Epoch 4/5\n",
      "3327/3327 [==============================] - 25s - loss: 0.0317 - acc: 0.9913 - val_loss: 0.1816 - val_acc: 0.9756\n",
      "Epoch 5/5\n",
      "3327/3327 [==============================] - 25s - loss: 0.0244 - acc: 0.9913 - val_loss: 0.2086 - val_acc: 0.9778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8df3358190>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bn_model.optimizer.lr /= 10\n",
    "bn_model.fit(conv_feat, to_categorical(trn_classes), batch_size=batch_size, nb_epoch=5, \n",
    "             validation_data=(conv_val_feat, to_categorical(val_classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bn_model.save_weights(path+\"models/640_loss_0.0472_acc_0.9856_val_loss_0.1373_val_acc_0.9778\")\n",
    "# bn_model.save_weights(path+\"models/loss_0.0244_acc_0.9913_val_loss_0.2086_val_acc_0.9778\")\n",
    "bn_model.load_weights(path+\"models/loss_0.0244_acc_0.9913_val_loss_0.2086_val_acc_0.9778\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = bn_model.predict(conv_test_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save_array(path+\"results/preds_640_val_acc_0.9778.dat\",predictions)\n",
    "# save_array(path+\"results/preds_640_loss_0.0244_acc_0.9913_val_loss_0.2086_val_acc_0.9778.dat\",predictions)\n",
    "save_array(path+\"results/stg2_pred_dense_noaug_no_pseudo.dat\",predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions[:,0].mean(),predictions[:,1].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 is fish class .., 1 no_fish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stage 2 predictions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12153 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_batches = image.ImageDataGenerator().flow_from_directory(path+\"test\", target_size=target_size,\n",
    "                class_mode=None, shuffle=False, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_test_feat = conv_model.predict_generator(test_batches, len(test_filenames))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stg2_predictions = bn_model.predict(conv_test_feat, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_array(path+\"results/stg2_pred_dense_noaug_no_pseudo.dat\",stg2_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Ensembling FCN and fully connected "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# fully_connected_preds_stg1 = load_array(path+\"results/preds_640_loss_0.0244_acc_0.9913_val_loss_0.2086_val_acc_0.9778.dat\")\n",
    "# fcn_preds_stg1 = load_array(path+\"results/pred_stg1_fullconv_aug_no_pseudo.dat\")\n",
    "\n",
    "\n",
    "fully_connected_preds_stg2 = load_array(path+\"results/stg2_pred_dense_noaug_no_pseudo.dat\")\n",
    "fcn_preds_stg2 = load_array(path+\"results/stg2_pred_fullconv_aug_no_pseudo.dat\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# final_stg1_weights = fully_connected_preds_stg1 + fcn_preds_stg1\n",
    "# final_stg1_weights /= 2.0\n",
    "\n",
    "final_stg2_weights = fully_connected_preds_stg2 + fcn_preds_stg2\n",
    "final_stg2_weights /= 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9577,  0.0423]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_stg2_weights[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save_array(path+\"results/final_stg1_weights_ensumble.dat\", final_stg1_weights)\n",
    "save_array(path+\"results/fishfinal_stg2_weights_ensumble.dat\", final_stg2_weights)\n",
    "\n",
    "#this resulted in 0.03 improvement in LB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "> Lookback >  use final_stg1_weights to do pseudo labeling on FCN (0.003 result improvement, not sure if training time and risk of overfitting is worth it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.9981e-01,   1.9445e-04]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now calculate predictions again with results of pseudo labeling and using full validation set:\n",
    "\n",
    "fcn_preds_stg1_WITH_pseudo = load_array(path+\"results/pred_stg1_fullconv_aug_WITH_pseudo.dat\")\n",
    "\n",
    "final_stg1_weights = fcn_preds_stg1_WITH_pseudo + fully_connected_preds_stg1 + fcn_preds_stg1\n",
    "final_stg1_weights /= 3.0\n",
    "\n",
    "final_stg1_weights[0:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(path+\"results/final_stg1_weights_ensumble_with_pseudo.dat\", final_stg1_weights)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
